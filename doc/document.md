# 设计文档
[TOC]


## 1. 介绍

### 1.1. 目的

本文档主要是针对文本分类系统这一产品的全方面介绍，包括功能、设计思路、系统结构以及接口和使用说明等，主要面向系统的使用者和维护者。

### 1.2. 范围

#### 1.2.1. 软件需求

该系统主要满足了用户自定义文本分类的功能，用户通过RESRful API的形式与系统进行交互，提供了参数配置、分类器训练、测试以及实时的文本分类等相关的接口。

#### 1.2.2. 软件功能

本系统针对短文本设计实现多类别分类。用户提供部分已标记数据，配置参数（也可默认），进行分类系统训练。训练结束后，可以输入未标记的数据进行文本分类。

## 2. 系统设计

### 2.1.  设计思路

对于短文本分类，短文本中包含的特征过少，同一类别下，短文本相似度低。必须对短文本补充上下文信息，丰富文本特征。

### 2.2. 总体结构

系统可以分为**online** 和**offline**两个部分。

#### 2.2.1.系统框图

offline是一个初始化以及配置的过程，在这个阶段，用户需要提供一些相关的配置信息以及训练数据，然后系统根据配置信息进行模型训练，并将训练好的模型存储到相关的位置。流程图如下图所示：
![STC_offline_flowchart](STC_offline_flowchart_1.png)
online是用户使用系统分类功能的过程，这个阶段，用户只需要提供需要分类的文档，然后系统可以实时的返回该文档的分类结果。流程图如下图所示：

![STC_online_flowchart](STC_online_flowchart_1.png)

#### 2.2.2. 细节描述

##### 2.2.2.1. offline训练向量化模型

###### 训练语料

由于系统针对短文本分类，仅仅采用已标注的训练数据训练模型，分类特征提取不充分。为了提高分类的泛化能力，必须为短文本补充相应的上下文。由于LDA和TFIDF的训练都是无监督学习，训练语料可以是无监督数据。系统默认提供一个1.5G的搜狗新闻作为训练语料，用户也可以自行上传XML文件。
训练语料格式：

| 字段    | 类型     | 说明                |
| :---- | ------ | ----------------- |
| 短文本   | string | 短文本数据，编码格式utf8    |
| 补充上下文 | string | 短文本的补充信息，编码格式utf8 |

如果短文本是新闻标题，可以为标题补充新闻内容作为其上下文。补充方式如：新闻标题+新闻内容

文件存储格式为：

```txt
corpus.txt
	文本1\n
	文本2\n
	文本3\n
	...
	文本n\n
```

注：corpus.txt为语料文件，保存在root/corpus/文件夹下，文件的每一行为一条合并后的文本，文本之间用“\n”作为间隔符。

合并规则举例如下：

- 新闻标题：

  中国大使投否决票遭英美围攻 现场脱稿霸气回击

- 新闻内容：

  在2017年2月的最后一天，联合国安理会当天就有关叙利亚化学武器问题的决议草案举行表决，中国与俄罗斯都行使了否决权，草案未获通过。也许是因为中国已不是第一次行使否决权，这条有关“中俄再否决西方制裁叙利亚决议”的消息并未在国内舆论中产生很大涟漪，尽管也有不少网友为中国点赞，称赞“理直气壮地行使权利才是负责任的大国行为”。......

- 合并后的文本：

  中国大使投否决票遭英美围攻 现场脱稿霸气回击。在2017年2月的最后一天，联合国安理会当天就有关叙利亚化学武器问题的决议草案举行表决，中国与俄罗斯都行使了否决权，草案未获通过。也许是因为中国已不是第一次行使否决权，这条有关“中俄再否决西方制裁叙利亚决议”的消息并未在国内舆论中产生很大涟漪，尽管也有不少网友为中国点赞，称赞“理直气壮地行使权利才是负责任的大国行为”。......（中间没有换行符）

###### 数据预处理

解析XML文件，抽取相应信息。对于中文文本数据，首先要对文本进行分词处理，分词可以采用分词工具包，本系统默认采用的是python的jieba工具包。可以通过custom_tokenize更改分词单元，要求custom_tokenize的类型必须是函数。分词之后，去除停用词以及各种符号，本系统直接将长度为1的词和停用词表中的词作为停用词。

- 输入TXT文件，格式如上。


- 对每行处理后将字符串写入文本。
- 输出TXT文本。
- 举例说明

输入每一行文本： 

"康师傅回应转卖废弃茶叶：下家承诺用废料做枕头"

结巴分词后：

[康师傅,回应,转卖,废弃,茶叶,：,下, 家,承诺,用,废料,做,枕头]

去除停用词后：

[康师傅,回应,转卖,废弃,茶叶,承诺,废料,枕头]

输出每一行文本：

"康师傅 回应 转卖 废弃 茶叶  承诺  废料  枕头"

注：每个词之间用一个**空白字符**作为分隔符。

###### 训练向量化模型

本系统使用了两种向量化模型，一种是基于词频的tf-idf模型，一种是基于主题的lda模型。通过两种模型转换的向量拼接成一个组合向量为文本分类向量。对于短文本而言，系统需要额外的大语料作为训练语料，训练向量化需要的模型。

**词典模型**

本系统利用sklearn.feature_extraction.text.CountVectorizer类处理文本生成词典模型。首先要将纯文档转化为词列表的形式，然后统计数据集中出现的全部词。出现的全部的词构成的集合，即为本语料的词典，词典中的每个词都对应一个id。通过词典模型可以将文本转换成的词袋矩阵。

- 功能：

如果词典不存在，首先生成词典模型。词典存在后，利用词典就将文本转换成相应的词袋矩阵。

- 输入：

可迭代的string矩阵，形如：

input_str = ["康师傅 回应 转卖 废弃 茶叶", “思源 焦点 公益 基金”  ,......] 

注：每个词之间用一个**空白字符**作为分隔符。

| type                      | shape           | 元素type |
| ------------------------- | --------------- | ------ |
| \<class 'numpy.ndarray'\> | (n_samplesL,1L) | string |

n_samples为样本个数。

- 生成模型：

type = \<class 'sklearn.feature_extraction.text.CountVectorizer'\>

生成词典模型，模型即为词典，利用pickle将其保存成文件存在硬盘。 

- 输出：

  字典模型

**tfidf模型**

 利用sklearn.feature_extraction.text.TfidfTransformer类处理词袋矩阵生成tfidf模型。tf-idf模型，其特征维度就是词典的词量大小，一篇文档的每个词都映射到相应id上，而在相应特征上的得分由两个因素共同决定，一是该词在这篇文档中出现的频率，一是包含该词的文档占文档总数的比例。一个词在一篇文档中出现次数越多，表明该词越重要。包含一个词的文档数越多，表明该词与这篇文档的相关性越低。通过tfidf模型将文本转换成tfidf矩阵。

举例说明tfidf值的计算：
词频 (TF) 是一词语出现的次数除以该文件的总词语数。假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是3/100=0.03。一个计算文件频率 (IDF) 的方法是文件集里包含的文件总数除以测定有多少份文件出现过“母牛”一词。所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 log(10,000,000 / 1,000)=4。最后的TF-IDF的分数为0.03 * 4=0.12。

- 功能：

如果模型不存在，首先生成tfidf模型。模型存在后，利用tfidf模型将词袋矩阵转换成相应的tfidf矩阵。

- 输入：词典模型

稀疏的词袋矩阵

| type                                    | shape                     | 元素type |
| --------------------------------------- | ------------------------- | ------ |
| \<class 'scipy.sparse.csr.csr_matrix'\> | (n_samplesL, n_featuresL) | int    |

n_samples为样本个数，n_features为词典词量大小。

- 生成模型：

type = \<class 'sklearn.feature_extraction.text.TfidfTransformer'\>

生成tfidf模型，利用pickle将其保存成文件存在硬盘。 

**lda模型**

利用lda.LDA处理词袋矩阵生成lda模型。lda模型，特征的维度可以由用户自定义(默认200)。tfidf有一个缺点就是当训练的文本较多时，词典的维度很大，但一篇文档中所包含的词数很少，这样文档的向量很稀疏。相关研究表明，一篇文档可以用少数几个主题表示，lda就是根据数据集的tfidf特征来训练指定数量的主题，并用文档与该主题的相关度作为特征。通过lda模型将文本转换成低纬度主题矩阵。

功能：

如果模型不存在，首先生成lda模型。模型存在后，利用lda模型将词袋矩阵转换成相应的稀疏矩阵。

输入：词典模型

转化稀疏的词袋矩阵

| type                                    | shape                     | 元素type |
| --------------------------------------- | ------------------------- | ------ |
| \<class 'scipy.sparse.csr.csr_matrix'\> | (n_samplesL, n_featuresL) | int    |

n_samples为样本个数，n_features为词典词量大小。

生成模型：

type =\<class 'lda.lda.LDA'\>

生成lda模型，利用pickle将其保存成文件存在硬盘。 

lda.LDA类参数设置：

| 参数       | 说明              | 默认   |
| -------- | --------------- | ---- |
| n_topics | 利用LDA生成的主题向量的维度 | 200  |
| n_iter   | 训练LDA模型需要迭代的次数  | 50   |

##### 2.2.2.2 offline训练分类器

######  训练数据

训练数据是已标注的数据，每个短文本都明确知道对应的类别。训练数据需要用户提供，按以下格式保存为TXT文件。

```txt
类别1.txt
	短文本1\n
	短文本2\n
	...
	短文本i\n
类别2.txt
	短文本i+1\n
	短文本i+2\n
	...
	短文本i+k\n
...
类别n.txt
	...
```

注：将类别名称作为文件名称，将已标注的文本放置在对应类别名称的文件中，所有文件保存在root/label/文件夹下，文件的每一行为一条短文本，文本之间用“\n”作为间隔符。

######   数据预处理

- 输入：


| 参数         | 类别        | 说明                                 |
| ---------- | --------- | ---------------------------------- |
| labels     | list      | 是一个字符串列表，如：[‘类别1’，‘类别2’，‘......’]  |
| texts      | 字符串或字符串列表 | 为字符串时，以文件方式接收数据；为字符串列表时，以列表方式接收数据。 |
| label_list | list      | 当texts为列表时，label_list为对应索引的文本的类别   |


- 输出：

| 返回值      | 类别   | 说明                        |
| -------- | ---- | ------------------------- |
| doc_list | list | 元素为字符串，形状为(n_samplesL,1L) |
| tag_list | list | 元素为整数，形状为(n_samplesL,1L)  |

######  向量化

向量化是指将一篇文档转化为相应的特征向量，特征是指能够代表这篇文档词或主题，对于一种向量化模型，特征的个数是固定，任意一篇文档都能映射到相应的特征空间。本系统的向量化分为两个部分，第一部分是tfidf模型的向量化；第二部分是lda模型的向量化。

tfidf模型向量化：tf-idf模型得到的向量维度是与词典中词的数量相等的，一般而言，词典中词的数量都是百万量级的，为了性能的考虑，需要通过特征选择的方法选择对于分类更有效的特征。通过对训练数据有监督的学习，可以从原有的特征中选择用户自定义K的特征作为特征选择后的特征。这样做可以保证参与运算的特征的维度处于可控的范围内，同时也减小了CPU和内存的消耗。

lda模型向量化：利用lda模型得到的是低纬度的主题向量。

- 功能：

将tfidf向量和lda向量拼接，得到一个新的文本向量。这个向量将作为文本在向量空间上的唯一映射。文本向量维度（合并后）= 维度(tfidf特征选择后)N + 维度(lda)M

- 输入：
| 参数       | 类别   | 说明                        |
| -------- | ---- | ------------------------- |
| doc_list | list | 元素为字符串，形状为(n_samplesL,1L) |
| tag_list | list | 元素为整数，形状为(n_samplesL,1L)  |


- 输出：

float类型的稀疏矩阵

| 返回值         | 类别                        | 说明                              |
| ----------- | ------------------------- | ------------------------------- |
| train_set_v | \<class 'numpy.ndarray'\> | 元素为float，形状为(n_samplesL,(N+M)L) |
| test_set_v  | \<class 'numpy.ndarray'\> | 元素为float，形状为(n_samplesL,(N+M)L) |

注：output\_v =[t\_1,t\_2,......,t\_N,l\_1,l\_2,......,l\_M]
t\_i 属于tfidf模型转换的向量，l\_j属于 lda模型转换的向量，0<=i<=N,0<=j<=M.N是tfidf转换向量的维度，M是lda转换向量的维度

###### 训练分类器

输入：

| 参数          | 类别                        | 说明   |
| ----------- | ------------------------- | ---- |
| train_set_v | \<class 'numpy.ndarray'\> | 训练文本 |
| test_set_v  | \<class 'numpy.ndarray'\> | 测试文本 |
| train_tag   | list                      | 训练类别 |
| test_tag    | list                      | 测试类别 |

输出：

| 返回值         | 类别   | 说明               |
| ----------- | ---- | ---------------- |
| result_dict | dict | 保存了分类器，返回分类器评估的值 |


#####  2.2.2.3. online预测


######   新文档

用户提供的未标注的文档。按以下格式保存为一个TXT文件。

```txt
predict_text.txt
	文本1\n
	文本2\n
	...
	文本n\n
```

注：将待标注的文本放置在一个文件中，保存在root/unlabel/文件夹下，文件的每一行为一条短文本，文本之间用“\n”作为间隔符。

###### 数据预处理

输入：

| 参数    | 类别        | 说明                                 |
| ----- | --------- | ---------------------------------- |
| texts | 字符串或字符串列表 | 为字符串时，以文件方式接收数据；为字符串列表时，以列表方式接收数据。 |

输出：

| 返回值      | 类别   | 说明                        |
| -------- | ---- | ------------------------- |
| doc_list | list | 元素为字符串，形状为(n_samplesL,1L) |

###### 向量化

输入：
| 参数       | 类别   | 说明                        |
| -------- | ---- | ------------------------- |
| doc_list | list | 元素为字符串，形状为(n_samplesL,1L) |

输出：

| 返回值        | 类别   | 说明                              |
| ---------- | ---- | ------------------------------- |
| test_set_v | list | 元素为float，形状为(n_samplesL,(N+M)L) |

注：output\_v =[t\_1,t\_2,......,t\_N,l\_1,l\_2,......,l\_M]
t\_i 属于tfidf模型转换的向量，l\_j属于 lda模型转换的向量，0<=i<=N,0<=j<=M.N是tfidf转换向量的维度，M是lda转换向量的维度

###### 分类预测

输入：

| 参数         | 类别   | 说明                              |
| ---------- | ---- | ------------------------------- |
| test_set_v | list | 元素为float，形状为(n_samplesL,(N+M)L) |
| topN       | int  | topN 为返回的类别个数                   |

注：output\_v =[t\_1,t\_2,......,t\_N,l\_1,l\_2,......,l\_M]
t\_i 属于tfidf模型转换的向量，l\_j属于 lda模型转换的向量，0<=i<=N,0<=j<=M.N是tfidf转换向量的维度，M是lda转换向量的维度

输出：

| 返回值         | 类别   | 说明                              |
| ----------- | ---- | ------------------------------- |
| labels_topN | list | 每个文本预测的类别，已经topN不等于0时，包含预测准确的概率 |
